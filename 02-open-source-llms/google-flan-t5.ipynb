{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"506fab2a-a50c-42bd-a106-c83a9d2828ea","cell_type":"code","source":"!rm -f minsearch.py\n!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T02:59:02.207379Z","iopub.execute_input":"2025-03-06T02:59:02.207704Z","iopub.status.idle":"2025-03-06T02:59:02.732298Z","shell.execute_reply.started":"2025-03-06T02:59:02.207674Z","shell.execute_reply":"2025-03-06T02:59:02.731278Z"}},"outputs":[{"name":"stdout","text":"--2025-03-06 02:59:02--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3832 (3.7K) [text/plain]\nSaving to: ‘minsearch.py’\n\nminsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n\n2025-03-06 02:59:02 (55.1 MB/s) - ‘minsearch.py’ saved [3832/3832]\n\n","output_type":"stream"}],"execution_count":2},{"id":"b4f7c447-d0c5-4968-8a1d-a1276caa39e8","cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T03:01:26.612654Z","iopub.execute_input":"2025-03-06T03:01:26.613010Z","iopub.status.idle":"2025-03-06T03:01:26.751974Z","shell.execute_reply.started":"2025-03-06T03:01:26.612987Z","shell.execute_reply":"2025-03-06T03:01:26.751281Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":10},{"id":"3ac947de-effd-4b61-8792-a6d7a133f347","cell_type":"code","source":"import requests \nimport minsearch\n\ndocs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\ndocs_response = requests.get(docs_url)\ndocuments_raw = docs_response.json()\n\ndocuments = []\n\nfor course in documents_raw:\n    course_name = course['course']\n\n    for doc in course['documents']:\n        doc['course'] = course_name\n        documents.append(doc)\n\nindex = minsearch.Index(\n    text_fields=[\"question\", \"text\", \"section\"],\n    keyword_fields=[\"course\"]\n)\n\nindex.fit(documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T02:59:06.685840Z","iopub.execute_input":"2025-03-06T02:59:06.686135Z","iopub.status.idle":"2025-03-06T02:59:08.851101Z","shell.execute_reply.started":"2025-03-06T02:59:06.686112Z","shell.execute_reply":"2025-03-06T02:59:08.850176Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<minsearch.Index at 0x7af500c8d930>"},"metadata":{}}],"execution_count":3},{"id":"8f087272-b44d-4738-9ea2-175ec63a058b","cell_type":"code","source":"def search(query):\n    boost = {'question': 3.0, 'section': 0.5}\n\n    results = index.search(\n        query=query,\n        filter_dict={'course': 'data-engineering-zoomcamp'},\n        boost_dict=boost,\n        num_results=5\n    )\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T02:59:12.670447Z","iopub.execute_input":"2025-03-06T02:59:12.670952Z","iopub.status.idle":"2025-03-06T02:59:12.675053Z","shell.execute_reply.started":"2025-03-06T02:59:12.670918Z","shell.execute_reply":"2025-03-06T02:59:12.674203Z"}},"outputs":[],"execution_count":4},{"id":"742ab881-499a-4675-83c4-2013ea1377b9","cell_type":"code","source":"def build_prompt(query, search_results):\n    prompt_template = \"\"\"\nYou're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\nUse only the facts from the CONTEXT when answering the QUESTION.\n\nQUESTION: {question}\n\nCONTEXT: \n{context}\n\"\"\".strip()\n\n    context = \"\"\n    \n    for doc in search_results:\n        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n    \n    prompt = prompt_template.format(question=query, context=context).strip()\n    return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T02:59:16.633931Z","iopub.execute_input":"2025-03-06T02:59:16.634235Z","iopub.status.idle":"2025-03-06T02:59:16.638897Z","shell.execute_reply.started":"2025-03-06T02:59:16.634212Z","shell.execute_reply":"2025-03-06T02:59:16.638014Z"}},"outputs":[],"execution_count":5},{"id":"988ece59-951a-4b32-ba3f-cb8efb66a9bb","cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T03:03:01.861055Z","iopub.execute_input":"2025-03-06T03:03:01.861387Z","iopub.status.idle":"2025-03-06T03:03:02.940465Z","shell.execute_reply.started":"2025-03-06T03:03:01.861363Z","shell.execute_reply":"2025-03-06T03:03:02.939694Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":11},{"id":"20ce6cfc-1e18-4c6e-97e4-f80d562ab6dc","cell_type":"code","source":"# max_length: Số lượng token tối đa trong output (mặc định: 100).\n# num_beams: Số lượng beam trong Beam Search (mặc định: 5). Beam Search giúp tìm kiếm câu trả lời tốt hơn bằng cách thử nhiều nhánh.\n# do_sample:\n# False: Dùng phương pháp greedy search hoặc beam search (mô hình luôn chọn từ có xác suất cao nhất).\n# True: Dùng phương pháp sampling (ngẫu nhiên hơn, phù hợp cho câu trả lời sáng tạo).\n# temperature: Điều chỉnh mức độ ngẫu nhiên của mô hình.\n# Giá trị thấp (≤ 1.0): Mô hình chọn từ có xác suất cao nhất (kết quả ổn định).\n# Giá trị cao (> 1.0): Mô hình có thể tạo văn bản đa dạng hơn.\n# top_k: Nếu sử dụng sampling, chỉ chọn trong k từ có xác suất cao nhất (giới hạn không gian tìm kiếm).\n# top_p: Nếu dùng Nucleus Sampling, chọn từ theo xác suất cộng dồn p (ví dụ: 0.95 giữ lại 95% xác suất cao nhất).\ndef llm(prompt, generate_params=None):\n    if generate_params is None:\n        generate_params = {}\n\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n    outputs = model.generate(\n        input_ids,\n        max_length=generate_params.get(\"max_length\", 100),\n        num_beams=generate_params.get(\"num_beams\", 5),\n        do_sample=generate_params.get(\"do_sample\", False),\n        temperature=generate_params.get(\"temperature\", 1.0),\n        top_k=generate_params.get(\"top_k\", 50),\n        top_p=generate_params.get(\"top_p\", 0.95),\n    )\n    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T03:03:08.741653Z","iopub.execute_input":"2025-03-06T03:03:08.741968Z","iopub.status.idle":"2025-03-06T03:03:08.747167Z","shell.execute_reply.started":"2025-03-06T03:03:08.741946Z","shell.execute_reply":"2025-03-06T03:03:08.746328Z"}},"outputs":[],"execution_count":12},{"id":"fe8bff3e-b672-42be-866b-f2d9bb217106","cell_type":"code","source":"def rag(query):\n    search_results = search(query)\n    prompt = build_prompt(query, search_results)\n    answer = llm(prompt)\n    return answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T03:03:11.464489Z","iopub.execute_input":"2025-03-06T03:03:11.464860Z","iopub.status.idle":"2025-03-06T03:03:11.468754Z","shell.execute_reply.started":"2025-03-06T03:03:11.464831Z","shell.execute_reply":"2025-03-06T03:03:11.468033Z"}},"outputs":[],"execution_count":13},{"id":"6785c049-9369-473f-9403-249dc8a94191","cell_type":"code","source":"rag(\"How do I enroll the data engineering zoomcamp course?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T03:03:55.156278Z","iopub.execute_input":"2025-03-06T03:03:55.156661Z","iopub.status.idle":"2025-03-06T03:03:56.782985Z","shell.execute_reply.started":"2025-03-06T03:03:55.156584Z","shell.execute_reply":"2025-03-06T03:03:56.782197Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'Go to https://www.atlassian.com/git/tutorials/setting-up-a-repository http://www.atlassian.com/git/tutorials/setting-up-a-repository http://www.atlassian.com/git/tutorials/setting-up-a-repository http://www.atlassian.com/git/tut'"},"metadata":{}}],"execution_count":16},{"id":"b1cc15a6-d53d-4973-9203-0ec22e539a15","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}